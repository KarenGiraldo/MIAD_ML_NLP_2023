{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b317f90-8758-4a0c-a26c-5e08fe1ebe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_educacion = pd.read_csv(\"noticias_educacion_sample.csv\")\n",
    "df_educacion['clase'] = 0\n",
    "df_politica = pd.read_csv(\"noticias_politica_sample.csv\")\n",
    "df_politica['clase'] = 1\n",
    "df_deportes = pd.read_csv(\"noticias_deportes_sample.csv\")\n",
    "df_deportes['clase'] = 2\n",
    "df_economia = pd.read_csv(\"noticias_economia_sample.csv\")\n",
    "df_economia['clase'] = 3\n",
    "df = pd.concat([df_educacion, df_politica, df_deportes, df_economia]).dropna().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5709ab4b-7533-4524-93f5-b50fe824759a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>description</th>\n",
       "      <th>clase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Como parte de la política de puertas abiertas ...</td>\n",
       "      <td>2022-02-08T19:12:01.737Z</td>\n",
       "      <td>La CAN abre convocatorias para pasantías en Co...</td>\n",
       "      <td>La Comunidad Andina de Naciones abrió la posib...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>El programa, que cumple 30 años desde su prime...</td>\n",
       "      <td>2022-05-14T18:02:23.629Z</td>\n",
       "      <td>Colfuturo apoyará a 1.526 profesionales colomb...</td>\n",
       "      <td>Los beneficiarios, en su mayoría, realizaron e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Estudiar una carrera universitaria en Colombia...</td>\n",
       "      <td>2022-10-19T09:45:01.712Z</td>\n",
       "      <td>¿Cómo estudiar becado en la mejor universidad ...</td>\n",
       "      <td>Según el ranking de Times Higher Education, la...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Escuche aquí el episodio número 27 de Finanzas...</td>\n",
       "      <td>2021-04-07T17:56:34.238Z</td>\n",
       "      <td>Consejos para financiar con inteligencia sus e...</td>\n",
       "      <td>Si estudiar es uno de sus principales objetivo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Durante el último año de la carrera universita...</td>\n",
       "      <td>2022-04-02T18:08:22.865Z</td>\n",
       "      <td>Pruebas Saber Pro: el listado de universidades...</td>\n",
       "      <td>Las universidades públicas presentaron preocup...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>495</td>\n",
       "      <td>Colombia sigue aumentando su endeudamiento ext...</td>\n",
       "      <td>2023-02-10T23:08:47.922Z</td>\n",
       "      <td>Deuda externa de Colombia representó el 52,8% ...</td>\n",
       "      <td>Así lo deja en evidencia el más reciente repor...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>496</td>\n",
       "      <td>La Agencia de Estados Unidos para el Desarroll...</td>\n",
       "      <td>2022-09-28T17:00:15.603Z</td>\n",
       "      <td>Lanzan convocatoria para apoyar a más de mil o...</td>\n",
       "      <td>La Usaid estará al frente de este proceso que ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>497</td>\n",
       "      <td>La inflación es uno de los mayores retos que e...</td>\n",
       "      <td>2023-02-25T03:41:20.639Z</td>\n",
       "      <td>Controlar la inflación no será tan fácil como ...</td>\n",
       "      <td>El aumento en los precios será una constante e...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>498</td>\n",
       "      <td>23 lugares icónicos de Cúcuta fueron decorados...</td>\n",
       "      <td>2022-12-07T17:16:46.317Z</td>\n",
       "      <td>Reapertura económica en la frontera: artesanas...</td>\n",
       "      <td>Cúcuta prepara la Ruta Navideña luego de haber...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>499</td>\n",
       "      <td>Durante las últimas semanas los bancos se han ...</td>\n",
       "      <td>2023-03-14T19:22:40.773Z</td>\n",
       "      <td>Tras anuncio del Gobierno Petro, el Banco Agra...</td>\n",
       "      <td>La ministra de Agricultura, Cecilia López, les...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1933 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  ... clase\n",
       "0         0  ...     0\n",
       "1         1  ...     0\n",
       "2         2  ...     0\n",
       "3         3  ...     0\n",
       "4         4  ...     0\n",
       "...     ...  ...   ...\n",
       "1928    495  ...     3\n",
       "1929    496  ...     3\n",
       "1930    497  ...     3\n",
       "1931    498  ...     3\n",
       "1932    499  ...     3\n",
       "\n",
       "[1933 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ad77021-06d7-4dc6-9822-89774d56ba94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Como parte de la política de puertas abiertas a las nuevas generaciones andinas, el secretario general de la Comunidad Andina de Naciones (CAN), Jorge Hernando Pedraza, anunció la convocatoria al XI programa de pasantías profesionales en el organismo andino “practiCAN”. Según se informó, podrán aplicar estudiantes universitarios que estén cursando el último semestre académico, egresados, técnicos y profesionales recién titulados en un tiempo no mayor a un año de diferentes escuelas y facultades universitarias de Bolivia, Colombia, Ecuador y Perú. “Esta iniciativa busca fortalecer una mayor vinculación de los jóvenes de los países miembros con el proceso andino de integración e impulsar que las nuevas generaciones asuman un rol más activo en la región desarrollando sus capacidades profesionales en las diversas áreas de la Secretaría General”, señaló el jefe del organismo. Podrán ser parte de “practiCAN 2022″, los jóvenes de las carreras Comercio Exterior, Relaciones Internacionales, Negocios Internacionales, Economía, Ingeniería Económica, Comercial, Industrial, de Telecomunicaciones, Eléctrica, Química, de la Energía, Ambiental, Civil, Transportes, Logística, Ingeniería de Sistemas, Técnicos y/o Tecnólogos Informáticos. Asimismo, profesionales de Química Farmacéutica, Medicina Veterinaria, Agronomía, Sociología, Geografía, Historia, Antropología, Ciencias Sociales, Derecho, Derecho Internacional Público, Ciencias Políticas, Administración, Contabilidad, Recursos Humanos, Psicología, Archivística y Gestión Documental, Periodismo, Diseño Gráfico, Community Manager, Audiovisuales, Infografista o carreras afines a las descritas. Las postulaciones se recibirán hasta el 20 de febrero próximo y los resultados se publicarán el 3 de marzo. Según informó la Comunidad Andina de Naciones, el inicio de las pasantías se podrán llevar a cabo en tres modalidades: presenciales, semipresenciales y virtuales dependiendo de cada postulación. Las pasantías, según se informó, no contarán con remuneración económica. Aquí se pueden conocer las condiciones específicas y el formulario de inscripción ¿Qué es la CAN? La Comunidad Andina, integrada por Bolivia, Colombia, Ecuador y Perú es un organismo internacional líder en integración en el continente, que trabaja por el mejoramiento de la calidad de vida de 111 millones de ciudadanos andinos. La CAN cuenta con diversos órganos e instituciones que integran el Sistema Andino de Integración (SAI), cuyo objetivo es alcanzar un desarrollo integral, equilibrado y autónomo, mediante la integración andina, con proyección hacia una integración sudamericana y latinoamericana. Desde el 26 de mayo de 1969, cuando se suscribió en Colombia, el Acuerdo de Cartagena, Tratado Constitutivo que fija los objetivos de la integración andina, define su sistema institucional y establece sus mecanismos y políticas, se puso en marcha el proceso andino de integración, conocido en ese entonces como Pacto Andino, hoy Comunidad Andina. Beneficios de la CAN a los ciudadanos Desde el sábado primero de enero de 2022, los bolivianos, colombianos, ecuatorianos y peruanos no tendrán que abonar ningún recargo adicional por el servicio de roaming internacional pospago en los países de la Comunidad Andina de Naciones (CAN). “Gracias a la Decisión 854, norma supranacional y de obligatorio cumplimiento, se aplicarán las mismas condiciones o planes tarifarios que el país de origen por los servicios de voz, SMS y datos”, explicó el organismo regional. Este beneficio para el bolsillo de los más de 111 millones de habitantes de la región se enmarca, según se explicó, en una norma que fue aprobada por los países miembros el 19 de febrero de 2020. “Esta histórica decisión contribuye a los esfuerzos de los países de la CAN para cerrar de manera eficaz y efectiva la brecha digital y dar cumplimiento al principio fundacional de nuestro organismo, que es el de mejorar la calidad de vida de los ciudadanos andinos”, afirmó el secretario general de la CAN, Jorge Hernando Pedraza. El jefe del organismo destacó que la eliminación de los cargos de roaming internacional se suma a los hitos recientemente alcanzados por la CAN, como el Estatuto Migratorio Andino, la Carta Ambiental Andina, la norma que facilita la circulación de los vehículos de uso privado de turistas, la próxima implementación del proyecto que facilita y digitaliza el comercio Intercom, entre otras.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, 'content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "270feecb-68ad-4dea-ade0-c22658cef4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>description</th>\n",
       "      <th>clase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Como parte de la política de puertas abiertas ...</td>\n",
       "      <td>2022-02-08T19:12:01.737Z</td>\n",
       "      <td>La CAN abre convocatorias para pasantías en Co...</td>\n",
       "      <td>La Comunidad Andina de Naciones abrió la posib...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>El programa, que cumple 30 años desde su prime...</td>\n",
       "      <td>2022-05-14T18:02:23.629Z</td>\n",
       "      <td>Colfuturo apoyará a 1.526 profesionales colomb...</td>\n",
       "      <td>Los beneficiarios, en su mayoría, realizaron e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Estudiar una carrera universitaria en Colombia...</td>\n",
       "      <td>2022-10-19T09:45:01.712Z</td>\n",
       "      <td>¿Cómo estudiar becado en la mejor universidad ...</td>\n",
       "      <td>Según el ranking de Times Higher Education, la...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Escuche aquí el episodio número 27 de Finanzas...</td>\n",
       "      <td>2021-04-07T17:56:34.238Z</td>\n",
       "      <td>Consejos para financiar con inteligencia sus e...</td>\n",
       "      <td>Si estudiar es uno de sus principales objetivo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Durante el último año de la carrera universita...</td>\n",
       "      <td>2022-04-02T18:08:22.865Z</td>\n",
       "      <td>Pruebas Saber Pro: el listado de universidades...</td>\n",
       "      <td>Las universidades públicas presentaron preocup...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>495</td>\n",
       "      <td>Colombia sigue aumentando su endeudamiento ext...</td>\n",
       "      <td>2023-02-10T23:08:47.922Z</td>\n",
       "      <td>Deuda externa de Colombia representó el 52,8% ...</td>\n",
       "      <td>Así lo deja en evidencia el más reciente repor...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>496</td>\n",
       "      <td>La Agencia de Estados Unidos para el Desarroll...</td>\n",
       "      <td>2022-09-28T17:00:15.603Z</td>\n",
       "      <td>Lanzan convocatoria para apoyar a más de mil o...</td>\n",
       "      <td>La Usaid estará al frente de este proceso que ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>497</td>\n",
       "      <td>La inflación es uno de los mayores retos que e...</td>\n",
       "      <td>2023-02-25T03:41:20.639Z</td>\n",
       "      <td>Controlar la inflación no será tan fácil como ...</td>\n",
       "      <td>El aumento en los precios será una constante e...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>498</td>\n",
       "      <td>23 lugares icónicos de Cúcuta fueron decorados...</td>\n",
       "      <td>2022-12-07T17:16:46.317Z</td>\n",
       "      <td>Reapertura económica en la frontera: artesanas...</td>\n",
       "      <td>Cúcuta prepara la Ruta Navideña luego de haber...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>499</td>\n",
       "      <td>Durante las últimas semanas los bancos se han ...</td>\n",
       "      <td>2023-03-14T19:22:40.773Z</td>\n",
       "      <td>Tras anuncio del Gobierno Petro, el Banco Agra...</td>\n",
       "      <td>La ministra de Agricultura, Cecilia López, les...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1933 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  ... clase\n",
       "0         0  ...     0\n",
       "1         1  ...     0\n",
       "2         2  ...     0\n",
       "3         3  ...     0\n",
       "4         4  ...     0\n",
       "...     ...  ...   ...\n",
       "1928    495  ...     3\n",
       "1929    496  ...     3\n",
       "1930    497  ...     3\n",
       "1931    498  ...     3\n",
       "1932    499  ...     3\n",
       "\n",
       "[1933 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cc3f3be-f201-4d14-9ba1-8a7b9bb772ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\carit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Download the NLTK Spanish stopwords if you haven't already\n",
    "spanish_stopwords = nltk.corpus.stopwords.words('spanish')\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "vectorizer_tfidf = TfidfVectorizer(max_features=2000, stop_words=spanish_stopwords, ngram_range=(1,3), lowercase=True)\n",
    "\n",
    "df = df[['content', 'clase']].dropna()\n",
    "\n",
    "# Train the TfidfVectorizer and transform the texts\n",
    "X_tfidf = vectorizer_tfidf.fit_transform(df['content']).todense()\n",
    "y = df['clase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f15edb-565a-4978-9b3e-d85298d49e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# train XGBoost model\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# compute precision, recall, and F1 score for each class\n",
    "num_classes = len(set(y_test))\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "for i in range(num_classes):\n",
    "    class_predicted = [1 if x == i else 0 for x in y_pred]\n",
    "    class_real = [1 if x == i else 0 for x in y_test]\n",
    "    precision = precision_score(class_real, class_predicted)\n",
    "    recall = recall_score(class_real, class_predicted)\n",
    "    f1 = f1_score(class_real, class_predicted)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# print results\n",
    "for i in range(num_classes):\n",
    "    print(\"Class {}: Precision: {:.2f}, Recall: {:.2f}, F1 score: {:.2f}\".format(i, precision_scores[i], recall_scores[i], f1_scores[i]))\n",
    "\n",
    "# get feature importances and vocabulary\n",
    "feature_importances = model.feature_importances_\n",
    "vocabulary = vectorizer_tfidf.get_feature_names()\n",
    "\n",
    "# print the top 10 tokens with the largest feature importance\n",
    "indices = feature_importances.argsort()[::-1]\n",
    "print(\"Top 10 tokens with largest feature importance:\")\n",
    "for i in range(10):\n",
    "    print(\"{:<15} {:.2f}%\".format(vocabulary[indices[i]], feature_importances[indices[i]]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5ff1ab-7c04-4a21-a081-143e9609eb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "import pandas as pd\n",
    "\n",
    "# normalize TF-IDF embeddings\n",
    "tfidf_embeddings_normalized = normalize(X_tfidf)\n",
    "\n",
    "# perform k-means clustering\n",
    "num_clusters = 4\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=1)\n",
    "kmeans.fit(tfidf_embeddings_normalized)\n",
    "\n",
    "# get feature importances and vocabulary\n",
    "feature_importances = kmeans.cluster_centers_\n",
    "vocabulary = vectorizer_tfidf.vocabulary_\n",
    "\n",
    "# print the top 5 most important features of each cluster\n",
    "print(\"Top n most important features of each cluster:\")\n",
    "for i in range(num_clusters):\n",
    "    indices = np.argsort(feature_importances[i])[::-1][:10]\n",
    "    features = [list(vocabulary.keys())[list(vocabulary.values()).index(index)] for index in indices]\n",
    "    print(\"Cluster {}: {}\".format(i+1, features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0405e45-8e50-4441-9f58-d73305b8cd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cosine_similarities = cosine_similarity(tfidf_embeddings_normalized[750].reshape(1, -1), tfidf_embeddings_normalized).reshape(-1)\n",
    "df['similarities'] = cosine_similarities\n",
    "grouped_similarities = df.groupby('clase')['similarities'].apply(list)\n",
    "\n",
    "# Determine the common range for the x-axis\n",
    "min_value = df['similarities'].min()\n",
    "max_value = df['similarities'].max()\n",
    "bins = 100\n",
    "common_range = (min_value, max_value)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (class_name, similarities) in enumerate(grouped_similarities.items()):\n",
    "    axes[i].hist(similarities, bins=bins, range=common_range, alpha=0.5, label=class_name, color=f\"C{i}\")\n",
    "    axes[i].set_title(f'Cosine Similarities for Class: {class_name}')\n",
    "    axes[i].set_xlabel('Cosine Similarity')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4470a0b7-c519-4d94-85ba-1ec84b792f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "import pandas as pd\n",
    "import umap.umap_ as umap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# perform UMAP dimensionality reduction on all data points\n",
    "umap_embeddings = umap.UMAP().fit_transform(tfidf_embeddings_normalized)\n",
    "\n",
    "# assign a color to each cluster label\n",
    "cmap = plt.get_cmap('viridis')\n",
    "colors = [cmap(i) for i in np.linspace(0, 1, num_clusters)]\n",
    "\n",
    "# plot all data points with different colors and labels for each cluster\n",
    "for i in range(num_clusters):\n",
    "    # get the indices of data points in this cluster\n",
    "    indices = kmeans.labels_ == i\n",
    "    # plot the data points with a different color and label name for this cluster\n",
    "    plt.scatter(umap_embeddings[indices, 0], umap_embeddings[indices, 1], c=[colors[i]], label=f'Cluster {i}')\n",
    "    \n",
    "# add legend to the plot\n",
    "plt.legend()\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee004d6-213f-48d4-aa59-903f2e8006ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "import pandas as pd\n",
    "\n",
    "df_subclusters = df_politica[['content', 'clase']].dropna()\n",
    "\n",
    "# Train the TfidfVectorizer and transform the texts\n",
    "X_tfidf = vectorizer_tfidf.fit_transform(df_subclusters['content']).todense()\n",
    "y = df['clase']\n",
    "\n",
    "# normalize TF-IDF embeddings\n",
    "tfidf_embeddings_normalized = normalize(X_tfidf)\n",
    "\n",
    "# perform k-means clustering\n",
    "num_clusters = 10\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=1)\n",
    "kmeans.fit(tfidf_embeddings_normalized)\n",
    "\n",
    "# get feature importances and vocabulary\n",
    "feature_importances = kmeans.cluster_centers_\n",
    "vocabulary = vectorizer_tfidf.vocabulary_\n",
    "\n",
    "# print the top 5 most important features of each cluster\n",
    "print(\"Top n most important features of each cluster:\")\n",
    "for i in range(num_clusters):\n",
    "    indices = np.argsort(feature_importances[i])[::-1][:10]\n",
    "    features = [list(vocabulary.keys())[list(vocabulary.values()).index(index)] for index in indices]\n",
    "    print(\"Cluster {}: {}\".format(i+1, features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f85f6bf-30cd-4c51-94ba-8aa455acd6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "import pandas as pd\n",
    "\n",
    "df_subclusters = df_deportes[['content', 'clase']].dropna()\n",
    "\n",
    "# Train the TfidfVectorizer and transform the texts\n",
    "X_tfidf = vectorizer_tfidf.fit_transform(df_subclusters['content']).todense()\n",
    "y = df['clase']\n",
    "\n",
    "# normalize TF-IDF embeddings\n",
    "tfidf_embeddings_normalized = normalize(X_tfidf)\n",
    "\n",
    "# perform k-means clustering\n",
    "num_clusters = 10\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=1)\n",
    "kmeans.fit(tfidf_embeddings_normalized)\n",
    "\n",
    "# get feature importances and vocabulary\n",
    "feature_importances = kmeans.cluster_centers_\n",
    "vocabulary = vectorizer_tfidf.vocabulary_\n",
    "\n",
    "# print the top 5 most important features of each cluster\n",
    "print(\"Top n most important features of each cluster:\")\n",
    "for i in range(num_clusters):\n",
    "    indices = np.argsort(feature_importances[i])[::-1][:10]\n",
    "    features = [list(vocabulary.keys())[list(vocabulary.values()).index(index)] for index in indices]\n",
    "    print(\"Cluster {}: {}\".format(i+1, features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4be068-44a1-4e08-99b8-a31f6d49ed2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "import pandas as pd\n",
    "\n",
    "df_subclusters = df_economia[['content', 'clase']].dropna()\n",
    "\n",
    "# Train the TfidfVectorizer and transform the texts\n",
    "X_tfidf = vectorizer_tfidf.fit_transform(df_subclusters['content']).todense()\n",
    "y = df['clase']\n",
    "\n",
    "# normalize TF-IDF embeddings\n",
    "tfidf_embeddings_normalized = normalize(X_tfidf)\n",
    "\n",
    "# perform k-means clustering\n",
    "num_clusters = 10\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=1)\n",
    "kmeans.fit(tfidf_embeddings_normalized)\n",
    "\n",
    "# get feature importances and vocabulary\n",
    "feature_importances = kmeans.cluster_centers_\n",
    "vocabulary = vectorizer_tfidf.vocabulary_\n",
    "\n",
    "# print the top 5 most important features of each cluster\n",
    "print(\"Top n most important features of each cluster:\")\n",
    "for i in range(num_clusters):\n",
    "    indices = np.argsort(feature_importances[i])[::-1][:10]\n",
    "    features = [list(vocabulary.keys())[list(vocabulary.values()).index(index)] for index in indices]\n",
    "    print(\"Cluster {}: {}\".format(i+1, features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f369cff3-4729-4687-af4f-c35547ce3545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Download the NLTK Spanish stopwords if you haven't already\n",
    "spanish_stopwords = nltk.corpus.stopwords.words('spanish')\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "vectorizer_tfidf = TfidfVectorizer(max_features=2000, stop_words=spanish_stopwords, ngram_range=(1,3), lowercase=True)\n",
    "\n",
    "df_codo = df[['content', 'clase']].dropna()\n",
    "\n",
    "# Train the TfidfVectorizer and transform the texts\n",
    "X_tfidf = vectorizer_tfidf.fit_transform(df_codo['content']).todense()\n",
    "\n",
    "# normalize TF-IDF embeddings\n",
    "tfidf_embeddings_normalized = normalize(X_tfidf)\n",
    "\n",
    "# elbow plot\n",
    "inertias = []\n",
    "for i in range(2, 50):\n",
    "    kmeans = KMeans(n_clusters=i, random_state=1)\n",
    "    kmeans.fit(tfidf_embeddings_normalized)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    \n",
    "plt.plot(range(2, 50), inertias)\n",
    "plt.title('Elbow Plot')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafc1941-bc4f-421d-937d-d9610d07c4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform k-means clustering with optimal number of clusters\n",
    "num_clusters = 6 # choose the number of clusters based on the elbow plot\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=1)\n",
    "kmeans.fit(tfidf_embeddings_normalized)\n",
    "\n",
    "# get feature importances and vocabulary\n",
    "feature_importances = kmeans.cluster_centers_\n",
    "vocabulary = vectorizer_tfidf.vocabulary_\n",
    "\n",
    "# print the top 5 most important features of each cluster\n",
    "print(\"Top n most important features of each cluster:\")\n",
    "for i in range(num_clusters):\n",
    "    indices = np.argsort(feature_importances[i])[::-1][:10]\n",
    "    features = [list(vocabulary.keys())[list(vocabulary.values()).index(index)] for index in indices]\n",
    "    print(\"Cluster {}: {}\".format(i+1, features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c247bd86-90ff-4c75-ade7-19dca889fceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import normalize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Train the TfidfVectorizer and transform the texts\n",
    "spanish_stopwords = nltk.corpus.stopwords.words('spanish')\n",
    "\n",
    "vectorizer_tfidf = TfidfVectorizer(max_features=2000, stop_words=spanish_stopwords)\n",
    "X_tfidf = vectorizer_tfidf.fit_transform(df['content']).todense()\n",
    "\n",
    "# Normalize the embeddings\n",
    "X_tfidf_normalized = normalize(X_tfidf)\n",
    "\n",
    "# Train a GMM model with a fixed number of clusters\n",
    "num_clusters = 4\n",
    "gmm = GaussianMixture(n_components=num_clusters, covariance_type='diag', random_state=0)\n",
    "gmm.fit(X_tfidf_normalized)\n",
    "\n",
    "# Predict the cluster assignments for each text\n",
    "cluster_assignments = gmm.predict(X_tfidf_normalized)\n",
    "\n",
    "# Calculate the average TF-IDF weights for each word in each cluster\n",
    "feature_weights = gmm.weights_[:, np.newaxis] * gmm.means_\n",
    "\n",
    "# Get the vocabulary from the TfidfVectorizer\n",
    "vocabulary = vectorizer_tfidf.vocabulary_\n",
    "\n",
    "# Print the top 10 most important words for each cluster\n",
    "print(\"Top 10 most important words for each cluster:\")\n",
    "for i in range(num_clusters):\n",
    "    indices = np.argsort(feature_weights[i])[::-1][:10]\n",
    "    features = [list(vocabulary.keys())[list(vocabulary.values()).index(index)] for index in indices]\n",
    "    print(\"Cluster {}: {}\".format(i+1, features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74fa52e-4c31-43b4-8180-5d4151900f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "df_educacion = pd.read_csv(\"noticias_educacion_sample.csv\")\n",
    "df_educacion['clase'] = 0\n",
    "df_politica = pd.read_csv(\"noticias_politica_sample.csv\")\n",
    "df_politica['clase'] = 1\n",
    "df_deportes = pd.read_csv(\"noticias_deportes_sample.csv\")\n",
    "df_deportes['clase'] = 2\n",
    "df_economia = pd.read_csv(\"noticias_economia_sample.csv\")\n",
    "df_economia['clase'] = 3\n",
    "df = pd.concat([df_educacion, df_politica, df_deportes, df_economia]).dropna().reset_index()\n",
    "\n",
    "# Initialize the sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define a function to get the compound sentiment score\n",
    "def get_sentiment(text):\n",
    "    if isinstance(text, str):\n",
    "        sentiment = analyzer.polarity_scores(text)\n",
    "        return sentiment['compound']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Apply the sentiment analysis to the 'content' column and store the results in a new column called 'sentiment'\n",
    "df.loc[0:1000, 'sentiment'] = df.loc[0:1000, 'content'].apply(get_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a144fdd1-d751-4427-9b2d-8f7e12c5e335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the DataFrame with the new 'sentiment' column\n",
    "df_positive = df[df['sentiment'].astype(float)>0.95].reset_index()\n",
    "for i in range(10):\n",
    "    print(df_positive.loc[i, 'headline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df566684-0468-4f61-842f-e5edaa0764cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the DataFrame with the new 'sentiment' column\n",
    "df_negative = df[df['sentiment'].astype(float)<-0.99].reset_index()\n",
    "for i in range(10):\n",
    "    print(df_negative.loc[i, 'headline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed7358a-365b-4086-a172-098d343440c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the Spanish language model\n",
    "nlp = spacy.load('es_core_news_lg')\n",
    "\n",
    "# Process the text with the language model\n",
    "doc = nlp(df_politica.loc[10, 'content'])\n",
    "\n",
    "# Print the entities found in the text\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ in ['PER', 'LOC']:\n",
    "        print(ent.text, ent.label_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
